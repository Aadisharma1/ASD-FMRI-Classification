{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b6b9b8-975f-41f4-a214-b8ea269088f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login (api key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e6f2f1-0be3-4a25-b7ce-8abbea8531fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import time\n",
    "import warnings\n",
    "import re \n",
    "import wandb # Import Weights & Biases\n",
    "\n",
    "# Neuroimaging libraries\n",
    "import nibabel as nib\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# PyTorch for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "\n",
    "# Scikit-learn for evaluation\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# Suppress unnecessary warnings for a cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# --- Login to W&B ---\n",
    "# IMPORTANT: It is highly recommended to log in via your terminal first.\n",
    "# 1. Open your terminal or Anaconda Prompt.\n",
    "# 2. Type 'wandb login' and paste your API key.\n",
    "# 3. Once done, you can comment out or delete the line below.\n",
    "# wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ff65b7-6a8c-40b4-a8fe-bc543e8db848",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = r'C:\\Users\\aadis\\abide'\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'abide_data', 'Outputs', 'cpac', 'nofilt_noglobal', 'func_preproc')\n",
    "PHENOTYPIC_FILE = os.path.join(BASE_DIR, 'Phenotypic_V1_0b_preprocessed1.csv')\n",
    "\n",
    "# --- 2.2: Model & Training Hyperparameters ---\n",
    "TARGET_SHAPE = (64, 64, 64)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 1e-4\n",
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 42\n",
    "PROJECT_NAME = \"ASD-fMRI-Classification\" # Name for your W&B project\n",
    "\n",
    "# --- 2.3: System Configuration ---\n",
    "NUM_WORKERS = 0\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Project Base Directory: {BASE_DIR}\")\n",
    "print(f\"Data Directory: {DATA_DIR}\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dc9220-ab8f-47ba-b473-0f4ca34d1008",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_phenotypic_data(phenotypic_file, data_dir):\n",
    "    \"\"\"Loads and prepares the phenotypic data from the CSV file.\"\"\"\n",
    "    print(\"--- Starting Data Loading and Preparation ---\")\n",
    "    if not os.path.exists(phenotypic_file):\n",
    "        print(f\"ERROR: Phenotypic file not found at {phenotypic_file}\")\n",
    "        return None\n",
    "    pheno_df = pd.read_csv(phenotypic_file, encoding='latin1')\n",
    "    \n",
    "    # Select the required columns\n",
    "    pheno_df = pheno_df[['SUB_ID', 'DX_GROUP']]\n",
    "    \n",
    "    # Apply the conversion only to the 'DX_GROUP' column.\n",
    "    pheno_df['DX_GROUP'] = pheno_df['DX_GROUP'].apply(lambda x: 1 if x == 1 else 0)\n",
    "    pheno_df.set_index('SUB_ID', inplace=True)\n",
    "    \n",
    "    # Search for files ending in .nii OR .nii.gz\n",
    "    all_files = glob(os.path.join(data_dir, '**', '*.nii*'), recursive=True)\n",
    "    if not all_files:\n",
    "        print(f\"ERROR: No .nii or .nii.gz files found.\")\n",
    "        return None\n",
    "        \n",
    "    subject_ids_from_files = []\n",
    "    for f in all_files:\n",
    "        basename = os.path.basename(f)\n",
    "        match = re.search(r'_(\\d{5,})', basename)\n",
    "        if match:\n",
    "            subject_ids_from_files.append(int(match.group(1)))\n",
    "            \n",
    "    valid_subjects_df = pheno_df.loc[pheno_df.index.isin(subject_ids_from_files)]\n",
    "    print(f\"Found {len(valid_subjects_df)} subjects with BOTH phenotypic data AND an fMRI scan.\")\n",
    "    if len(valid_subjects_df) == 0:\n",
    "        print(\"\\nCRITICAL ERROR: No matching subjects found.\")\n",
    "        return None\n",
    "    return valid_subjects_df\n",
    "\n",
    "class ABIDEDataset(Dataset):\n",
    "    \"\"\"Custom PyTorch Dataset for loading ABIDE fMRI data on-the-fly.\"\"\"\n",
    "    def __init__(self, subject_df, data_dir, target_shape):\n",
    "        self.subject_df = subject_df\n",
    "        self.target_shape = target_shape\n",
    "        self.subjects = self.subject_df.index.tolist()\n",
    "        self.file_paths = {}\n",
    "        # Search for files ending in .nii OR .nii.gz\n",
    "        all_filepaths = glob(os.path.join(data_dir, '**', '*.nii*'), recursive=True)\n",
    "        for f in all_filepaths:\n",
    "            basename = os.path.basename(f)\n",
    "            match = re.search(r'_(\\d{5,})', basename)\n",
    "            if match:\n",
    "                sub_id = int(match.group(1))\n",
    "                self.file_paths[sub_id] = f\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subjects)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject_id = self.subjects[idx]\n",
    "        filepath = self.file_paths.get(subject_id)\n",
    "        if filepath is None:\n",
    "            # BUG FIX: Return a numerical placeholder instead of a string\n",
    "            return torch.zeros((1, *self.target_shape)), -1, -1\n",
    "        try:\n",
    "            img = nib.load(filepath)\n",
    "            data = img.get_fdata()\n",
    "            if data.ndim == 4:\n",
    "                data = data.mean(axis=-1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filepath}: {e}\")\n",
    "            # BUG FIX: Return a numerical placeholder instead of a string\n",
    "            return torch.zeros((1, *self.target_shape)), -1, -1\n",
    "        zoom_factors = [t / s for t, s in zip(self.target_shape, data.shape)]\n",
    "        resized_data = zoom(data, zoom_factors, order=1)\n",
    "        mean, std = np.mean(resized_data), np.std(resized_data)\n",
    "        normalized_data = (resized_data - mean) / std if std > 0 else resized_data\n",
    "        tensor_data = torch.from_numpy(normalized_data).float().unsqueeze(0)\n",
    "        label = self.subject_df.loc[subject_id, 'DX_GROUP']\n",
    "        # Returning subject_id for potential debugging, site is removed\n",
    "        return tensor_data, label, subject_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ed9960-b78c-4657-8120-67821c795730",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple3DCNN(nn.Module):\n",
    "    \"\"\"A simple 3D CNN to serve as a performance baseline.\"\"\"\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(Simple3DCNN, self).__init__()\n",
    "        self.conv_block1 = self._create_conv_block(1, 8)\n",
    "        self.conv_block2 = self._create_conv_block(8, 16)\n",
    "        self.conv_block3 = self._create_conv_block(16, 32)\n",
    "        self.flattened_size = 32 * (TARGET_SHAPE[0] // 8) * (TARGET_SHAPE[1] // 8) * (TARGET_SHAPE[2] // 8)\n",
    "        self.classifier = nn.Sequential(nn.Linear(self.flattened_size, 128), nn.ReLU(), nn.Dropout(0.5), nn.Linear(128, num_classes))\n",
    "    def _create_conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1), nn.BatchNorm3d(out_channels), nn.ReLU(), nn.MaxPool3d(2))\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x); x = self.conv_block2(x); x = self.conv_block3(x)\n",
    "        x = x.view(x.size(0), -1); x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "def get_pretrained_3d_resnet(num_classes=2):\n",
    "    \"\"\"Loads a pre-trained 3D ResNet and adapts it for our 1-channel fMRI data.\"\"\"\n",
    "    print(\"Loading and adapting pre-trained 3D ResNet...\")\n",
    "    model = models.video.r3d_18(weights=models.video.R3D_18_Weights.KINETICS400_V1)\n",
    "    # Correctly access the first convolutional layer in the stem\n",
    "    original_weights = model.stem[0].weight.data\n",
    "    new_weights = original_weights.mean(dim=1, keepdim=True)\n",
    "    # Create a new Conv3d layer and assign the averaged weights\n",
    "    new_first_layer = nn.Conv3d(1, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
    "    new_first_layer.weight.data = new_weights\n",
    "    # Replace the original first layer (which is the 0-th element of the stem Sequential module)\n",
    "    model.stem[0] = new_first_layer\n",
    "    \n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af59fd78-04cd-44af-b081-318a97c5d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, val_loader, optimizer, criterion, epochs, device):\n",
    "    \"\"\"A reusable function to handle the training and validation loop.\"\"\"\n",
    "    best_val_auc = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, labels, _ in train_loader:\n",
    "            if -1 in labels: continue\n",
    "            inputs, labels = inputs.to(device), labels.to(device).long()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        all_labels, all_preds = [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels, _ in val_loader:\n",
    "                if -1 in labels: continue\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                preds = torch.softmax(outputs, dim=1)[:, 1]\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "        \n",
    "        val_auc = 0.0\n",
    "        if len(all_labels) > 0:\n",
    "            val_auc = roc_auc_score(all_labels, all_preds)\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | Validation AUC: {val_auc:.4f}\")\n",
    "            if val_auc > best_val_auc:\n",
    "                best_val_auc = val_auc\n",
    "                torch.save(model.state_dict(), 'best_model_in_fold.pth')\n",
    "        \n",
    "        # --- W&B Logging ---\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"validation_auc\": val_auc,\n",
    "            \"training_loss\": train_loss / len(train_loader)\n",
    "        })\n",
    "            \n",
    "    if os.path.exists('best_model_in_fold.pth'):\n",
    "        model.load_state_dict(torch.load('best_model_in_fold.pth'))\n",
    "    return model, best_val_auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1510e26-7394-452c-b917-9d51037c6c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pheno_df = load_phenotypic_data(PHENOTYPIC_FILE, DATA_DIR)\n",
    "\n",
    "# --- SCALE DOWN THE DATASET FOR DRAFTING RESULTS ---\n",
    "if full_pheno_df is not None:\n",
    "    # Set this fraction to control the dataset size. 0.12 is ~12% or ~10GB.\n",
    "    # To run on the full dataset, comment out this entire block.\n",
    "    #sample_fraction = 0.04\n",
    "    \n",
    "    # Use train_test_split to create a smaller, stratified sample.\n",
    "    # We use the '_' to discard the larger part of the split that we don't need.\n",
    "   # _, full_pheno_df = train_test_split(\n",
    "    #    full_pheno_df,\n",
    "     #   train_size=sample_fraction,\n",
    "      #  stratify=full_pheno_df['DX_GROUP'], # Stratify by diagnosis to keep the class ratio\n",
    "       # random_state=RANDOM_STATE\n",
    "    #)\n",
    "    #print(f\"\\n--- SCALING DOWN DATASET FOR FASTER DRAFTING ---\")\n",
    "    #print(f\"Using a {int(sample_fraction*100)}% stratified sample: {len(full_pheno_df)} subjects total.\")\n",
    "# ---------------------------------------------\n",
    "\n",
    "if full_pheno_df is not None:\n",
    "    subject_ids = full_pheno_df.index.values\n",
    "    labels = full_pheno_df['DX_GROUP'].values # Use the 1D diagnosis column for splitting\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    fold_results = []\n",
    "    \n",
    "    print(f\"\\nStarting {N_SPLITS}-Fold Cross-Validation...\")\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(subject_ids, labels)):\n",
    "        print(f\"\\n===== FOLD {fold+1}/{N_SPLITS} =====\")\n",
    "        \n",
    "        run = None # Initialize run to None\n",
    "        try:\n",
    "            run = wandb.init(\n",
    "                project=PROJECT_NAME,\n",
    "                group=\"Cross-Validation-Draft\", # Use a different group for draft runs\n",
    "                name=f\"Fold-{fold+1}\",\n",
    "                reinit=True\n",
    "            )\n",
    "        except wandb.errors.CommError as e:\n",
    "            print(f\"W&B Error: Could not initialize run. Please ensure you are logged in.\")\n",
    "            print(f\"To log in, run 'wandb login' in your terminal and paste your API key.\")\n",
    "            print(f\"Original error: {e}\")\n",
    "            # We can choose to break or continue without wandb, let's break for now.\n",
    "            break\n",
    "\n",
    "        train_subjects_df = full_pheno_df.iloc[train_idx]\n",
    "        val_subjects_df = full_pheno_df.iloc[val_idx]\n",
    "        train_dataset = ABIDEDataset(train_subjects_df, DATA_DIR, TARGET_SHAPE)\n",
    "        val_dataset = ABIDEDataset(val_subjects_df, DATA_DIR, TARGET_SHAPE)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "        \n",
    "        model = get_pretrained_3d_resnet().to(DEVICE)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        _, best_auc = train_and_evaluate(\n",
    "            model=model, train_loader=train_loader, val_loader=val_loader,\n",
    "            optimizer=optimizer, criterion=criterion, epochs=EPOCHS, device=DEVICE\n",
    "        )\n",
    "        \n",
    "        print(f\"Fold {fold+1} Best AUC: {best_auc:.4f}\")\n",
    "        \n",
    "        if run: # Check if wandb.init was successful\n",
    "            wandb.summary[\"best_fold_auc\"] = best_auc\n",
    "            run.finish()\n",
    "\n",
    "else:\n",
    "    print(\"\\nExecution stopped due to data loading errors.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
